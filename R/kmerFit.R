#' Fit k-mer Probe Set Models
#'
#' @description
#' After performing probe-level summarization across samples, this function applies probe
#' set aggregation to obtain k-mer level estimates of affinity for a specified list of
#' k-mers. By default, probe affinities are corrected for position bias. Bias
#' correction is performed such that the mean cross-probe intensity for each k-mer is
#' typically unchanged, and only serves to reduce the cross-probe variance within probe sets
#' for each k-mer.
#'
#' @param se SummarizedExpeirment of probe-level affinity summaries generated by
#'         \code{probeFit}.
#' @param kmers character vector of k-mers to predict.
#' @param positionbias logical whether to correct for bias due to position
#'        of k-mer along probe sequence. (default = TRUE)
#' @param method character name of method to use for estimating cross-probe variance
#'        in each k-mer probe set. Currently, the non-iterative DerSimonian-Laird ("dl")
#'        and two-step Dersimonian-Laird ("dl2") methods are supported. (default = "dl2")
#' @param outlier_cutoff numeric threshold for filtering probes from k-mer
#'        probe sets before fitting each k-mer level model. The threshold is
#'        applied to the absolute value of an approximate robust studentized residual
#'        computed for each probe in each probe set and can be turned off by
#'        setting the value to NULL. By default, approximate 0.5% tails are trimmed.
#'        (default = \code{qnorm(0.995)})
#' @param outlier_maxp numeric threshold on maximum proportion of probes to filter
#'        for each k-mer probe set. This is to prevent over-filtering based on the
#'        approximate residual threshold. (default = 0.2)
#' @param contrasts logical whether to compute contrasts for all conditions against a
#'        specified \code{baseline} column. (default = TRUE)
#' @param baseline character name of baseline condition to use to calculate contrasts
#'        for all other conditions. Should match a column name of SummarizedExperiment object.
#'        If NULL, the baseline condition is chosen by looking for a column ending in "ref" or "REF".
#'        If a unique baseline column isn't found, an error is thrown. (default = NULL)
#' @param .filter integer specifying level of probe filtering to
#'        perform prior to estimating affinities. See \code{pbmFilterProbes}
#'        for more details on probe filter levels. (default = 1)
#' @param .trim interger vector of length two specifying start and end
#'        of probe sequence to be used. Default is based on the universal
#'        PBM probe design where only leading 36nt should be used. 
#'        Ignored if NULL. (default = c(1, 36))
#' 
#' @return
#' SummarizedExperiment of estimated k-mer affinities and differences.
#'
#' @references
#' If using \code{method = "dl2"} cross-probe variance estimator:
#' \itemize{
#' \item DerSimonian, R., & Kacker, R. (2007). Random-effects model for meta-analysis of clinical trials: an update. Contemporary Clinical Trials, 28(2), 105-114.
#' }
#' If using \code{method = "dl"} cross-probe variance estimator:
#' \itemize{
#' \item DerSimonian, R., & Laird, N. (1986). Meta-analysis in clinical trials. Controlled Clinical Trials, 7(3), 177-188.
#' }
#' Cross-probe variance estimation code adapted from:
#' \itemize{
#' \item Viechtbauer, W. (2010). Conducting meta-analyses in R with the metafor package. Journal of Statistical Software, 36(3), 1-48. URL: http://www.jstatsoft.org/v36/i03/
#' }
#'
#' @importFrom dplyr select_ group_by left_join ungroup do mutate
#' @importFrom tidyr unnest spread
#' @export
#' @author Patrick Kimes
kmerFit <- function(se, kmers, positionbias = TRUE, method = c("dl2", "dl"),
                    contrasts = TRUE, baseline = NULL,
                    outlier_cutoff = qnorm(0.995), outlier_maxp = 0.2,
                    .filter = 1L,
                    .trim = if (.filter > 0L) { c(1, 36) } else { NULL }) {

    stopifnot(is(se, "SummarizedExperiment"))
    method <- match.arg(method)

    stopifnot(is.null(outlier_cutoff) ||
              (is.numeric(outlier_cutoff) & outlier_cutoff > 0))
    stopifnot(is.numeric(outlier_maxp) && outlier_maxp >= 0 && outlier_maxp <= 1)

    ## check if specificed 'baseline' is valid
    if (contrasts) {
        if (is.null(baseline)) {
            baseline <- grep("ref$", colnames(se), value = TRUE, ignore.case = TRUE)
            if (length(baseline) > 1) {
                stop("Too many candidate baseline states in column names: ",
                     paste0(baseline, collapse = ", "), ".\n",
                     "Specify correct baseline column name w/ 'baseline ='.")
            }
        } else {
            if (! baseline %in% colnames(se)) {
                stop(baseline, " is not a column name of the SummarizedExperiment.\n",
                     "Specify correct baseline column name w/ 'baseline ='.")
            }
        }
    }
    
    ## check kmers specified
    kmers <- checkKmers(kmers, verb = FALSE)

    ## check Sequence info in rowData
    se <- checkProbeSequences(se, verb = FALSE)

    ## filter probes
    se <- pbmFilterProbes(se, .filter)

    ## trim probe sequences
    se <- trimProbeSequences(se, .trim)

    ## find mapping between kmers and probes
    ovnames <- intersect(names(rowData(se)), c("Row", "Column", "ID", "Sequence"))
    kmermap <- mapKmers(rowData(se)[, ovnames, drop = FALSE], kmers)

    ## use ordering from input 'kmers'
    kmermap$seq <- factor(kmermap$seq, levels = kmers)

    ## create table of probe-level betas
    bdat <- broom::tidy(se, "beta", long = FALSE, .filter = 0L)
    bdat <- dplyr::left_join(kmermap, bdat, by = setdiff(ovnames, "Sequence"))

    if (positionbias) {
        ## reshape table and compute probe-set bias per k-mer
        bdat <- dplyr::select(bdat, -probe_idx, -orient, -Column, -Row, -Sequence)
        bdat <- tidyr::gather(bdat, sample, value, -pos, -ID, -seq)

        bdat <- dplyr::group_by(bdat, seq, sample)
        bdat <- dplyr::mutate(bdat, pmean = mean(value, na.rm = TRUE),
                              pbias = value - pmean)
        bdat <- dplyr::ungroup(bdat)

        ## compute average bias over 2% bins
        bdat <- dplyr::group_by(bdat, sample)
        bdat <- dplyr::mutate(bdat, qbin = as.numeric(ggplot2::cut_number(pmean, 1 / .02)))
        bdat <- dplyr::group_by(bdat, sample, qbin, pos)
        bdat <- dplyr::mutate(bdat, pbias = mean(pbias, na.rm = TRUE))
        bdat <- dplyr::ungroup(bdat)
        bdat <- dplyr::mutate(bdat, value = value - pbias)
        bdat <- dplyr::select(bdat, -pmean, -qbin)

        ## create table of adjusted beta estimates, samples as cols (so slow..)
        bdat_beta <- dplyr::select(bdat, seq, pos, ID, sample, value)
        bdat_beta <- tidyr::spread(bdat_beta, sample, value)
        bdat_beta <- dplyr::arrange(bdat_beta, seq, ID, pos)

        ## ## create table of adjusted beta estimates, samples as cols (so slow..)
        ## bdat_pbias <- dplyr::select(bdat, seq, pos, ID, sample, value)
        ## bdat_pbias <- tidyr::spread(bdat_pbias, sample, value)
        ## bdat_pbias <- dplyr::arrange(bdat_pbias, seq, ID, pos)
    } else {
        bdat_beta <- dplyr::select(bdat, seq, pos, ID, one_of(colnames(se)))
        bdat_beta <- dplyr::arrange(bdat_beta, seq, ID, pos)
    }
    
    ## extract consistent table columns
    rowdat <- dplyr::select(bdat_beta, -one_of(colnames(se)))

    ## create table of sd estimates, samples as cols
    bdat_sd <- broom::tidy(se, "sd", long = FALSE, .filter = 0L)
    bdat_sd <- dplyr::select(bdat_sd, -Sequence, -Column, -Row)
    bdat_sd <- dplyr::left_join(rowdat, bdat_sd, by = "ID")
    bdat_sd <- dplyr::arrange(bdat_sd, seq, ID, pos)

    ## turn beta, sd values into tall table and join
    bdat_beta <- tidyr::gather(bdat_beta, condition, beta, -seq, -pos, -ID)
    bdat_sd <- tidyr::gather(bdat_sd, condition, sd, -seq, -pos, -ID)

    ## tidyr join operations takes time, so check order of rows and throw error if not same 
    stopifnot(bdat_beta$condition == bdat_sd$condition)
    stopifnot(bdat_beta$seq == bdat_sd$seq)
    stopifnot(bdat_beta$pos == bdat_sd$pos)
    stopifnot(bdat_beta$ID == bdat_sd$ID)

    ## simple merge if rows are same order
    adat <- bdat_beta
    adat$sd <- bdat_sd$sd

    ## only keep necessary columns
    adat <- dplyr::select(bdat, condition, seq, beta, sd)
    
    if (!is.null(outlier_cutoff)) {
        ## compute quick studentized residuals
        ## -- cross-probe var estimate as MAD
        ## -- cross-probe point estimate as median
        adat <- dplyr::group_by(adat, condition, seq)
        adat <- dplyr::mutate(adat, probeZ = (beta - median(beta, na.rm = TRUE)) /
                                        sqrt(mad(beta, na.rm = TRUE)^2 + sd^2))
        if (outlier_maxp < 1) {
            ## compute quantiles of residuals
            adat <- dplyr::mutate(adat,
                                  probeZq = rank(-abs(probeZ), na.last = TRUE, ties.method = "first"),
                                  probeZq = probeZq / sum(!is.na(probeZ)))
            ## prevent more than maxp to be rejected at any cutoff
            adat <- dplyr::mutate(adat, probeZ = ifelse(probeZq > outlier_maxp, 0, probeZ))
            adat <- dplyr::select(adat, -probeZq)
        }
        adat <- dplyr::ungroup(adat)

        ## filter out probes
        adat <- dplyr::mutate(adat, beta = ifelse(abs(probeZ) > outlier_cutoff, NA, beta))
        adat <- dplyr::select(adat, -probeZ)
    }

    ## compute probe set mixed effects model for each k-mer and condition
    adat <- tidyr::nest(adat, -condition, -seq)
    if (method == "dl") {
        adat <- dplyr::mutate(adat,
                              res = lapply(data, function(x) {
                                  ## filter out NA probe results
                                  x <- dplyr::filter(x, !is.na(beta), !is.na(sd))
                                  dl_estimator(x$beta, x$sd^2, nrow(x))
                              }))
    } else if (method == "dl2") {
        adat <- dplyr::mutate(adat,
                              res = lapply(data, function(x) {
                                  ## filter out NA probe results
                                  x <- dplyr::filter(x, !is.na(beta), !is.na(sd))
                                  dl2_estimator(x$beta, x$sd^2, nrow(x))
                              }))
    } else {
        stop("specified method is invalid")
    }

    adat <- dplyr::mutate(adat, beta = vapply(res, `[[`, numeric(1), "betaME"))
    adat <- dplyr::mutate(adat, betaVar = vapply(res, `[[`, numeric(1), "varME"))

    ## clean up all results
    bdat <- dplyr::select(adat, condition, seq, beta)
    bdat <- tidyr::spread(bdat, condition, beta)
    bdat <- dplyr::rename(bdat, "blbeta" = !!baseline)
    bdat <- tidyr::gather(bdat, condition, beta, -seq, -blbeta)

    ## tidy results to assays
    assaylist <- list(affinityEstimate = .tidycol2mat(adat, "beta", kmers, colnames(se)),
                      affinityVariance = .tidycol2mat(adat, "betaVar", kmers, colnames(se)))


    ## rearrange data to compute contrast covariances if needed
    if (contrasts) {
        ares <- dplyr::mutate(adat, data = mapply(function(d, r) {
            d$resid <- d$beta - r$betaME
            d$tau2 <- r$tau2
            d$totvar <- d$sd^2 + d$tau2
            d
        }, d = data, r = res, SIMPLIFY = FALSE))
        ares <- dplyr::select(ares, condition, seq, data)
        ares <- tidyr::spread(ares, condition, data)
        ares <- dplyr::rename(ares, "bldata" = !!baseline)
        ares <- tidyr::gather(ares, condition, data, -seq, -bldata)

        ## compute empirical covariance and upperbound (assuming indep sampling error)
        ares <- dplyr::mutate(ares,
                              ecov = mapply(function(x, y) {
                                  sum(x$resid * y$resid, na.rm = TRUE) /
                                      (sum(!is.na(x$resid) & !is.na(y$resid)) - 1)
                              }, x = data, y = bldata))
        ares <- dplyr::mutate(ares, 
                              covmax = mapply(function(x, y) {
                                  sqrt(x$tau2[1] * y$tau2[1])
                              }, x = data, y = bldata))
        ares <- dplyr::mutate(ares, ecovT = pmin(ecov, covmax, na.rm = TRUE))

        ## compute total variance of difference using error covariance estimate
        ares <- dplyr::mutate(ares, 
                              dvar = mapply(function(d1, d2, e) {
                                  v1 <- 1 / sum(1/d1$totvar, na.rm = TRUE)
                                  v2 <- 1 / sum(1/d2$totvar, na.rm = TRUE)
                                  ccv <- sum(1 / (d1$totvar * d2$totvar), na.rm = TRUE) * e * v1 * v2
                                  v1 + v2 - 2 * ccv
                              }, d1 = data, d2 = bldata, e = ecovT))
        ares <- dplyr::select(ares, seq, condition, dvar)

        ## clean up and tidy contrasts results
        bdat <- dplyr::mutate(bdat, M = beta - blbeta)
        bdat <- dplyr::mutate(bdat, A = (beta + blbeta) / 2)
        assaylist <- c(assaylist,
                       list(contrastDifference = .tidycol2mat(bdat, "M", kmers, colnames(se)),
                            contrastAverage = .tidycol2mat(bdat, "A", kmers, colnames(se)),
                            contrastVariance = .tidycol2mat(ares, "dvar", kmers, colnames(se))))
    }
    
    rdat <- dplyr::select(adat, seq)
    rdat <- rdat[match(kmers, rdat$seq), ]

    SummarizedExperiment(assays = assaylist, rowData = rdat)
}


## helper to turn tidy table column into matrix for SE
.tidycol2mat <- function(x, cn, km, s) {
    x <- dplyr::select(x, seq, condition, !!cn)
    x <- tidyr::spread(x, condition, !!cn)
    x <- x[match(km, x$seq), sort(names(x)), ]
    x <- as.matrix(dplyr::select(x, -seq))
    if (!all(colnames(x) %in% s))
        stop("column names do not match specified samples")
    if (ncol(x) < length(s)) {
        x <- cbind(matrix(NA, nrow(x), length(s) - ncol(x)), x)
        colnames(x)[seq_len(length(setdiff(s, colnames(x))))] <- setdiff(s, colnames(x))
    }
    x[, s, drop = FALSE]
}
